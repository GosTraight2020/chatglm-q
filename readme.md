
# chatglm-q

[ChatGLM-6B](https://huggingface.co/THUDM/chatglm-6b) optimized for quantization and exporting to ONNX.
