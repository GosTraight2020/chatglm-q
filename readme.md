
# chatglm-q

A [ChatGLM](https://huggingface.co/THUDM/chatglm-6b) reference implementation without Huggingface `transformers`. Optimized for int8 quantization and ONNX export.
