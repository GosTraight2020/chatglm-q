
# chatglm_q

A [ChatGLM](https://huggingface.co/THUDM/chatglm-6b) reference implementation without Huggingface `transformers`. Optimized for int8 quantization with ONNXRuntime.
